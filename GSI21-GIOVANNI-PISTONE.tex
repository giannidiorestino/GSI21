\documentclass[runningheads]{llncs}
%
\usepackage[hyphens]{url}
\usepackage[pdftex]{graphicx}
\usepackage{amsmath,amssymb}
%\usepackage{accents}
%\usepackage{amsthm}
\usepackage{array}
\usepackage{bm}
\usepackage{color}
\usepackage{etex}
\usepackage{extramacros}
%\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{stackrel}
\usepackage{cleveref}

%\usepackage{graphicx}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
\renewcommand\UrlFont{\color{blue}\rmfamily}


\begin{document}
%
\title{Statistical bundle of the transport model\thanks{The author is
    supported by de Castro Statistics, Collegio Carlo Alberto. He is a member of INdAM-GNAMPA.}}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{Giovanni Pistone\inst{1}\orcidID{0000-0003-2841-788X}}
%
\authorrunning{G. Pistone}
%
\institute{de Castro Statistics, Collegio Carlo Alberto, Piazza
  Arbarello 8, 10122 Torino, Italy \\
  \email{giovanni.pistone@carloalberto.org}\\
  \url{https://www.giannidi orestino.it}}
%
\maketitle  
%
\begin{abstract} We derive a gradient flow equation in the Statistical Bundle whose singular points are the optimal plans of a trasportation problem.
  %We discuss the statistical bundle of the Kantorovich transport model. We assume a finite sample space. We discuss the relation of the splitting of the general statistical bundle both with the gradient flow of the Kantorovich cost and with the statistics of exponential additive models. This preliminary version is submitted to the GSI21 Conference as an extended abstract. For this reason, we do not list primary references in the present version. 
%
  \keywords{Statistical bundle \and Kantorovich transport
    model \and Gradient flow \and Exponential additive model}
\end{abstract}
%
\section{Introduction}

Consider a product sample space $\Omega=\Omega_1 \times \Omega_2$ and the marginal mappings $X \colon \Omega \to \Omega_1$, $Y \colon \Omega \to \Omega_2$. Both factors are finite sets, $n_i = \# \Omega_i$. If $\gamma$ is a positive probability function on $\Omega$, we denote by $\gamma_1$ and $\gamma_2$ the two margins. We denote by $L^2(\gamma)$, $L^2(\gamma_1)$ and $L^2(\gamma_2)$ the Euclidean spaces of real random variables with the given weight, and by $L^2_0(\gamma)$, $L^2_0(\gamma_1)$ and $L^2_0(\gamma_2)$ the spaces of random variables which are centered for the given probability function.

We aim studying evolution equations on the vector bundle defined in the non-parametric Information Geometry (IG) of the open probability simplex of the sample space $\Omega$. See the tutorial \cite{pistone:2020-NPCS} and the applications of this formalism in \cite{pistone|rogantin:2015.1502.06718} \cite{pistone:2018lagrange}, \cite{chirco|malago|pistone:2020-arXiv:2009.09431}. A very short review follows below.

If $\Delta^\circ(\Omega)$ is the open probability simplex, we define the \emph{statistical bundle} $S\Delta^\circ(\Omega)$ to be the set of all couples $(\gamma,u)$ with $\gamma \in \Delta^\circ(\Omega)$ and $u$ a random variable such that $\expectat \gamma u = 0$. The fiber at $\gamma$ is $S_\gamma\Delta^\circ(\Omega)= L^2_0(\gamma)$. The IG dualistic structure of \cite{amari|nagaoka:2000} is taken into account by saying that the dual statistical bundle $S^*\Delta^\circ(\Omega)$ is the bundle whose fibers are the duals $L^2_0(\gamma)^* = L^2_0(\gamma)$. In the following of the present note, we will make the abuse of notations of identifying the statistical bundle and its dual. Two dual affine connections are defined via the parallel transports
\begin{gather*}
  \mtransport \gamma \mu \colon S_\gamma \Delta^\circ(\Omega) \ni v \mapsto \frac \gamma \mu v \in S_\mu \Delta^\circ(\Omega) \ , \\
  \etransport \mu \gamma \colon S_\mu \Delta^\circ(\Omega) \ni w \mapsto w - \expectat \gamma w \in S_\gamma \Delta^\circ(\Omega) \ , \\
\end{gather*}
so that $\scalarat \mu {\mtransport \gamma \mu v} w = \scalarat \gamma v {\etransport \mu \gamma w}$. The inner product is trasported between fibers by $\scalarat \nu u v = \scalarat \gamma {\mtransport \mu \gamma u}{\etransport \mu \gamma v}$.

For each smooth curve $t \mapsto \gamma(t) \in \Delta^\circ(\Omega)$ the \emph{velocity} (or \emph{score}) is $\velocity \gamma(t) = \derivby t \log \gamma(t)$. We look at $t \mapsto (\gamma(t),\velocity \gamma(t))$ as a curve in the statistical bundle. In the duality we have
\begin{equation} \label{eq:1} \derivby t \expectat {\gamma(t)} u = \scalarat {\gamma(t)} {u - \expectat {\gamma(t)} u} {\velocity \gamma(t)} \ .
\end{equation}
The mapping $\gamma \mapsto u - \expectat \gamma u$ is the \emph{gradient mapping} of $\gamma \mapsto \expectat \gamma u$. It is a section of the statistical bundle. For each section $F$ we define the \emph{evolution equation} $\velocity \gamma = F(\gamma)$. By writing $\velocity \gamma = \dot \gamma/\gamma$, we see that the evolution equation in our sense is equivalent to the Ordinary Differential Equation (ODE) $\dot \gamma = \gamma F(\gamma)$.

 
Given a sub-manifold of $\Delta^\circ(\Omega)$, each fiber $S_\gamma$ of the statistical bundle splits to define the proper sub-statistical bundle. We are interested in the sub-manifold associated to transport plans, see for example, \cite{santambrogio:2015otap}. Let be given $\mu_1 \in \Delta^\circ(\Omega_1)$ and $\mu_2 \in \Delta^\circ(\Omega_2)$. The \emph{transport model} with margins $\mu_1$ and $\mu_2$ is the statistical model
\begin{equation*} \Gamma(\mu_1,\mu_2) = \setof{\gamma \in \Delta(\Omega)}{\gamma(\cdot,+) = \mu_1, \gamma(+,\cdot) = \mu_2} \ .
\end{equation*}

Without restriction of generality, we assume the two margins $\mu_1$ and $\mu_2$ to be strictly positive. Our sub-manifold is the \emph{open transport model}
\begin{equation*} \Gamma^\circ(\mu_1,\mu_2) = \setof{\gamma \in \Delta^\circ(\Omega)}{\gamma(\cdot,+) = \mu_1, \gamma(+,\cdot) = \mu_2} \ .
\end{equation*}

Marginalization acts on velocities as a conditional expectation. If $t \mapsto \gamma(t)$ is a smooth curve in the open transport model, then \cref{eq:1} with $u = f \circ X$ gives \begin{equation*} 0 = \derivby t \expectat {\mu_1} f =  \derivby t \expectat {\gamma(t)} {f(X)} = \scalarat {\gamma(t)}  {f(X)} {\velocity \gamma(t)} = \scalarat {\mu_1}  f {{\velocity \gamma(t)}_1} \ , \end{equation*} with ${\velocity \gamma(t)}_1(X) = \condexpectat {\gamma(t)} {\velocity \gamma(t)} X$. Similarly on the other projection. It follows that $\condexpectat {\gamma(t)} {\velocity \gamma(t)} X = 0$ and $\condexpectat {\gamma(t)} {\velocity \gamma(t)} Y = 0$. This suggests the characterization of the velocity bundle of the open transport model we develop in the following section.

\section{ANOVA}

Let us discuss more in detail the relevant splittings. We use the statistical language of Analysis of Variance (ANOVA). Recall that $\gamma \in \Delta^\circ(\Omega)$. The linear sub-spaces of $L^2(\gamma)$ which , respectively, express the \emph{$\gamma$-grand-mean}, the two \emph{$\gamma$-simple effects}, and the \emph{$\gamma$-interactions}, are
\begin{equation}\label{eq:ANOVA-spaces} \begin{aligned} B_0(\gamma) &\sim \reals, \\ B_1(\gamma) &= \setof{f\circ X}{f \in L^2_0(\gamma_1)},\\ B_2(\gamma) &= \setof{f\circ Y}{f \in L^2_0(\gamma_2)},\\ B_{12}(\gamma) &= (B_0(\gamma) + B_1(\gamma) + B_2(\gamma))^\perp, \end{aligned} \end{equation}
where the orthogonality is computed in the $\gamma$ weight, that is in the inner product of $L^2(\gamma)$, $\scalarat \gamma u v = \expectat \gamma {uv}$. Each element of the space $B_0(\gamma) + B_1(\gamma) + B_2(\gamma)$ has the form $u = u_0 + f_1(X) + f_2(Y)$, where $u_0 = \expectat \gamma u$ and $f_1,f_2$ are uniquely defined. 

\begin{proposition}For each $\gamma \in \Delta(\Omega)$ there exist a unique orthogonal splitting
%
\begin{equation*}
%
  L^2(\gamma) = \reals \oplus \left(B_1(\gamma) + B_2(\gamma)\right) \oplus B_{12}(\gamma) \ . 
\end{equation*}
Namely, each $u \in L^2(\gamma)$ can be written uniquely as
\begin{equation}
 \label{eq:ANOVA}
 u = u_0 + (u_1 + u_2) + u_{12} \ ,
\end{equation}
where $u_0=\expectat \gamma u$ and $(u_1+u_2)$ is the $\gamma$-orthogonal projection of $u-u_0$ unto
$(B_1(\gamma) + B_2(\gamma))$.
\end{proposition}

\begin{proof}Each couple of spaces in \cref{eq:ANOVA-spaces} has trivial intersection $\set{0}$, hence the splitting in \cref{eq:ANOVA} is unique. As $\expectat \gamma u = u_0$ and $B_0(\gamma)$ is orthogonal to $B_1(\gamma)+B_2(\gamma)$, then $u_{12}$ is the orthogonal projection of $u - \expectat \gamma u$ unto $(B_1(\gamma)+B_2(\gamma))^\perp$, while $u_1+u_2$ is the orthogonal projection of $u$ onto $(B_1(\gamma)+B_2(\gamma))$. \qed
\end{proof}

Let us derive a system of equations for the simple effects. By definition, $u_{12} = (u - u_0) - (u_1 + u_2)$ is $\gamma$-orthogonal to each $g_1 \in B_1(\gamma)$ and each $g_2 \in B_2(\gamma)$. The orthogonal projections on $B_1(\gamma)$ and $B_2(\gamma)$ are the conditional expectation with respect to $X$ and $Y$, respectively,
%
  \begin{align*}
    0 &= \condexpectat \gamma {(u-u_0) - (u_1+u_2)}{X}  \ , \\
   0 &= \condexpectat \gamma {(u-u_0) - (u_1+u_2)}{Y} \ .
  \end{align*}
  %

Assume zero mean, $u_0=0$. We have the system of equations
\begin{align*}
  \condexpectat \gamma u X &=  u_1 + \condexpectat \gamma {u_2} {X} \\
  \condexpectat \gamma u Y &= \condexpectat \gamma {u_1} {Y} + u_2
\end{align*}

The ANOVA decomposition proves the existence of $u_1$ and $u_2$.  The following $(n_1+n_2)\times(n_1+n_2)$ linear system holds:
\begin{equation*}
\begin{cases}
  \sum_{y \in \Omega_2} \gamma_{2|1}(y|x)u(x,y) &= u_1(x) + \sum_{y \in \Omega_2} \gamma_{2|1}(y|x) u_2(y) , \quad x \in \Omega_1 \\
  \sum_{x \in \Omega_1} \gamma_{1|2}(x|y)u(x,y) &= \sum_{x \in \Omega_1} \gamma_{1|2}(x|y) u_1(x)  + u_2(y) , \quad y \in \Omega_2
\end{cases}
\end{equation*}
where we use the conditional probabilities $\gamma_{2|1}(y|x) \gamma_1(x) = \gamma_{1|2}(x|y) \gamma_2(y) = \gamma(x,y)$, $x \in \Omega_1$ and $y \in \Omega_2$.

We write the previous system in matrix form with blocks
\begin{gather*}
  \Gamma_{2|1} = [\gamma_{2|1}(y|x)]_{x \in \Omega_1, y \in \Omega_2} \in \reals^{n_1 \times n_2} \\
  \Gamma_{1|2} = [\gamma_{1|2}(x|y)]_{x \in \Omega_1, y \in \Omega_2} \in \reals^{n_1 \times n_2} \\
  \bm u_1 = (u_1(x) | x \in \Omega_1) \\
  \bm u_2 = (u_2(x) | x \in \Omega_2) \\
  \bm u_{2|1} = (\sum_{y \in \Omega_2} u(x,y)\gamma_{2|1}(y|x) | x \in \Omega_1) \\
  \bm u_{1|2} = (\sum_{x\in\Omega_1} u(x,y)\gamma_{1|2}(x|y) | x \in \Omega_2) \ ,
\end{gather*}
as 
\begin{equation}
\label{eq:block}
  \begin{bmatrix}
    I_{n_1} & \Gamma_{2|1} \\ \Gamma_{1|2}^T & I_{n_2}
  \end{bmatrix}
  \begin{bmatrix}
    \bm u_1 \\ \bm u_2
  \end{bmatrix}
=
\begin{bmatrix}
  \bm u_{2|1} \\ \bm u_{1|2}
\end{bmatrix}
\end{equation}

The block matrix is not globally invertible because the kernel contains the vector $\bm 1 _{n_1} \oplus \bm 1_{n_2}$, hence we look for a generalised inverse of the block matrix  which  exists uniquely because of the interpretation as the orthogonal projection of $f \in L_0^2(\gamma)$ onto $(B_1(\gamma) + B_2(\gamma))$. Generalised inverses of the Shur complements $(I_{n_1}-\Gamma_{2|1}\Gamma_{1|2}^T)$ and $(I_{n_2}-\Gamma_{1|2}^T\Gamma_{2|1})$, if available, suggests the following generalised block inversion formula:
%
\begin{equation}
\label{eq:blocksolve}
\begin{bmatrix}
    I_{n_1} & \Gamma_{2|1} \\ \Gamma_{1|2}^T & I_{n_2}
  \end{bmatrix} ^+ =
  \begin{bmatrix}
    (I_{n_1}-\Gamma_{2|1}\Gamma_{1|2}^T)^{+} & - \Gamma_{2|1} (I_{n_2}-\Gamma_{1|2}^T\Gamma_{2|1})^{+} \\
 - \Gamma_{1|2}^T (I_{n_1}-\Gamma_{2|1}\Gamma_{1|2}^T)^{+} & (I_{n_2}-\Gamma_{1|2}^T\Gamma_{2|1})^{+} 
\end{bmatrix} \ 
\end{equation}

\begin{proposition}The matrices $P = \Gamma_{2|1}\Gamma_{1|2}^T$ and $Q = \Gamma_{1|2}^T\Gamma_{2|1}$ are Markov, with invariant probability $\gamma_1$ and $\gamma_2$ respectively, and strictly positive, hence ergodic. It holds
  \begin{equation*}
    (I-P)^+ = \sum_{k=0}^\infty P^k \ , \quad (I-Q)^+ = \sum_{k=0}^\infty Q^k \ . 
  \end{equation*}
\end{proposition}

\begin{proof}The element $P_{x_1x_2}$, $x_1,x_2 \in \Omega_1$, of $P = \Gamma_{2|1}\Gamma_{1|2}^T \in \reals^{\Omega_1 \times \Omega_2}$ is
%
\begin{equation*}
  P_{x_1x_2} = \sum_{y \in \Omega_2} \gamma_{2|1}(y|x_1) \gamma_{1|2}(x_2|y) \ ,
\end{equation*}
%
so that $P$ is a Markov matrix with strictly positive entries and stationary probability $\gamma_1$. Because of the ergodic theorem, $P^n \to P^\infty = \bgamma_1^T \bm 1$, $n \to \infty$, so that 
%
\begin{equation*}
\lim_{n\to\infty} \left(\sum_{k=0}^n P^k\right)(I-P) = \lim_{n\to\infty} \left(I - P^{n+1}\right) = I - P^\infty \ , 
\end{equation*}
%
so that for each $\bm f_1 \in L(\Omega_1)$ it holds
%
\begin{equation*}
  \lim_{n\to\infty} \left(\sum_{k=0}^n P^k\right)(I-P) \bm f_1 = \bm f_1 - \expectat {\gamma_1} {\bm f_1} \ ,
\end{equation*}
%
where the last term is the orthogonal projection $\Pi_{\gamma_1}$ of $\bm f_1$ onto $L_0(\gamma_1)$. \qed
\end{proof}

\begin{proposition}The generalised inverses $(I-P)^+$ and $(I-Q)^+$ are defined and 
%
  \begin{equation*}
  \begin{bmatrix}
    \bm f_1 \\ \bm f_2
  \end{bmatrix}
=
    \begin{bmatrix}
      (I - P)^+ & - \Gamma_{2|1}(I - Q)^+ \\
- \Gamma_{1|2}(I-P)^+ & (I-Q)^+
    \end{bmatrix}
    \begin{bmatrix}
      \bm f_{2|1} \\ \bm f_{1|2}
    \end{bmatrix}
  \end{equation*}
%
solves \cref{eq:block}.
\end{proposition}

\begin{proof}
  Let us write
%
\begin{equation*}
  (I_{n_1}-\Gamma_{2|1}\Gamma_{1|2}^T)^{+} = \lim_{n\to\infty} \left(\sum_{k=0}^n (\Gamma_{2|1}\Gamma_{1|2}^T)^k\right) \Pi_{\gamma_1}  
\end{equation*}
%
so that
%
\begin{equation*}
  (I_{n_1}-\Gamma_{2|1}\Gamma_{1|2}^T)^{+}(I_{n_1}-\Gamma_{2|1}\Gamma_{1|2}^T) = \Pi_{\gamma_1} \ ,
\end{equation*}
%
because $\Pi_{\gamma_1} (I_{n_1}-\Gamma_{2|1}\Gamma_{1|2}^T) = (I_{n_1}-\Gamma_{2|1}\Gamma_{1|2}^T)$.

Similarly, for $Q = \Gamma_{2|1}^T\Gamma_{1|2}$, we have
%
\begin{equation*}
  (I_{n_1}-\Gamma_{2|1}^T\Gamma_{1|2})^{+}(I_{n_1}-\Gamma_{2|1}^T\Gamma_{1|2}) = \Pi_{\gamma_2} \ ,
\end{equation*}
%
It follows that \cref{eq:block} is solved with \cref{eq:blocksolve}.\qed
\end{proof}

We now apply the ANOVA decomposition to the study of the open transport model geometry as a sub-bundle of the statistical bundle $S\Delta^\circ(\Omega)$. Let us write the ANOVA decomposition of the statistical bundle as
  \begin{equation*}
    S_\gamma \Delta^\circ(\Omega) = (B_1(\gamma) + B_2(\gamma)) \oplus B_{12}(\gamma) \ .
  \end{equation*}
 

  \begin{proposition} \begin{enumerate}\item Let $t \mapsto \gamma(t) \in \Gamma^\circ(\mu_1,\mu_2)$ be a smooth curve with $\gamma(0)=\gamma$.   Then the velocity at $\gamma$ belongs to the interactions, $\velocity \gamma(0) \in B_{12}(\gamma)$.
      \item Given any interaction $v \in B_{12}(\gamma)$, the curve $t \mapsto \gamma(t) = (1+tv)\gamma$ stays in $\Gamma^\circ(\mu_1,\mu_2)$ for $t$ in a neighborhood of 0 and $v = \velocity\gamma(0)$.
  \end{enumerate}
\end{proposition}

\begin{proof}
We already know that $\expectat {\gamma} {\velocity\gamma(0)} = 0$. For each $f \in L^2_0(\mu_1)$, we have $f \circ X \in B_1(\gamma)$, so that 
%
    \begin{equation*}
    \scalarat \gamma {f \circ X}{\velocity\gamma(0)} = \left. \derivby t \expectat {\gamma(t)} {f \circ X} \right|_{t=0} = \left. \derivby t \expectat {\gamma_1(t)} {f} \right|_{t=0} = \left. \derivby t \expectat {\mu_1} {f} \right|_{t=0} = 0 \ .
    \end{equation*}
%
    Same argument in the other margin.
    
Given $v \in B_{12}(\gamma)$, we show there exist an open interval I around 0 such that $I \ni t \mapsto \gamma(t) = (1+tv)\gamma$ is a regular curve in $\Gamma^\circ(\mu_1,\mu_2) \subset \Delta^\circ(\Omega)$. It is indeed a curve in $\Delta^\circ(\Omega)$ because $\sum_{x,y} \gamma(x,y)(1+tv(x,y)) = \expectat \gamma {1+tv} = 1$ and because $\gamma(x,y)(1+tV(x,y)) > 0$ for all $x,y$, provided $t \in ]- (\max v)^{-1}, - (\min v)^{-1}[$.  The velocity exists,
%
\    \begin{equation*}
     \velocity\gamma(0) = \left.  \derivby t \logof{(1+tv)\gamma} \right|_{t=0} = \left. \frac v {1+tv} \right|_{t=0} = v \ .
    \end{equation*}
%
Finally, let us compute the margins of $(x,y) \mapsto \gamma(x,y;t) = (1+tv(x,y))\gamma(x,y)$. The argument is the same for both margins. For all $x \in \Omega_1$,
%
\begin{multline*}
  \sum_y (1+tv(x,y))\gamma(x,y) = \gamma_1(x) + t \sum_y v(x,y)\gamma(x,y) = \\ \mu_1(x) + t \expectat \gamma {(X = x) v} = \mu_1(x) \ ,
\end{multline*}
%
where $(X = x)$ is the indicator function of $\set{X = x}$. \qed
\end{proof}
 
In conclusion, the IG structure of the open transport model is the following.

\begin{proposition} The \emph{transport model bundle} with margins $\mu_1$ and $\mu_2$ is the sub-statistical bundle
%
\begin{equation} \label{eq:2}
  S\Gamma^\circ(\mu_1,\mu_2) = \setof{(\gamma,v)}{\gamma\in\Gamma^\circ(\mu_1,\mu_2), \condexpectat \gamma v X = \condexpectat \gamma v Y = 0} \ .
\end{equation}
The transport $\mtransport {\gamma} {\bar\gamma}$ maps the fiber at $\gamma$ to the fiber at $\bar\gamma$.
\end{proposition}

\begin{proof}
The first statement has been already proved. If $\gamma,\bar\gamma \in \Gamma^\circ (\mu_1,\mu_2)$ and $v \in S_{\gamma}\Gamma^\circ(\mu_1,\mu_2)$, we have
\begin{equation*}
  \condexpectat {\bar\gamma} {\mtransport {\gamma} {\bar\gamma} v} X \propto \condexpectat {\gamma}{\frac {\bar\gamma}{\gamma} \mtransport {\gamma} {\bar\gamma} v} X = \condexpectat {\gamma} v X = 0 \ . 
\end{equation*}
\end{proof}
\begin{remark}
  In the statistical bundle setup, at each $p \in \Delta^\circ(\Omega)$ there is a chart $s_p$ derived from the exponential representation, namely
\begin{equation*}
 s_p \colon \Delta^\circ(\Omega) \ni q \mapsto \log \frac q p - \expectat \gamma {\log \frac q p} = u \in S_p\Delta^\circ(\Omega) \ ,
\end{equation*}
so that
\begin{equation*}
  u \mapsto \euler^{u - K_p(u)} \cdot p \ , \quad K_p(u) = \log \expectat p {\euler^u} \ .
\end{equation*}

The sub-manifold of the transport model is flat in the mixture geometry and there is no simple expression of the exponential coordinate. However, the splitting of the dual statistical bundle suggests a mixed parameterization of $\Delta^\circ(\Omega)$. If $u \in S_\gamma \Delta^\circ(\Omega)$, consider the splitting $u = u_1+u_2+u_{1,2}$.
If $1 + u_{12} > 0$, then
\begin{equation*}
  u \mapsto \gamma(u) \propto \euler^{u_1+u_2} (1+u_{12})\cdot \gamma \in \Delta^\circ(\Omega)\ ,
\end{equation*}
where $(1+u_{12}) \cdot \gamma \in \Gamma^\circ(\gamma_1,\gamma_2)$ and, for each given $u_{12}$, we have an exponential family orthogonal to $\Gamma^\circ(\gamma_1,\gamma_2)$.
\end{remark}

\section{Gradient flow of the transport problem}
\label{sec:gradientflow}
Let us discuss the optimal transport problem in the framework of the transport model bundle of \cref{eq:2}. Let be given a cost function $c \colon \Omega_1 \times \Omega_2 = \Omega \to \reals$ and define the expected cost function $C \colon \Delta(\Omega)\ni \gamma \mapsto \expectat \gamma c$.

\begin{proposition}The function $\gamma \mapsto C(\gamma)$ restricted to the open transport model $\Gamma^\circ(\mu_1,\mu_2)$ has statistical gradient in $S\Gamma^\circ(\mu_1,\mu_2)$ given by
%
\begin{equation}\label{eq:gradient}
 \grad C \colon \gamma \mapsto c_{12,\gamma} = c - c_{0,\gamma} - (c_{1,\gamma} + c_{2,\gamma}) \in S_\gamma\Gamma^\circ(\mu_1,\mu_2)  \ . 
\end{equation}
\end{proposition}

\begin{proof}
For each smooth curve $t \mapsto \gamma(t)$, $\gamma(0) = \gamma$, we have 
\begin{equation*}
  \derivby t C(\gamma(t)) = \derivby t \expectat {\gamma(t)} c = \expectat {\gamma(t)} {c \velocity \gamma (t)} = \scalarat {\gamma(t)} {c_{12,\gamma(t)}} {\velocity \gamma(t)} \ .
\end{equation*}
where we have used the splitting at $\gamma(t)$,
\begin{equation*}
  c = c_{0,\gamma(t)} + (c_{1,\gamma(t)} + c_{2,\gamma(t)}) + c_{12,\gamma(t)}
\end{equation*}
together with the fact that the velocity $\velocity\gamma(t)$ is an interaction.\qed \end{proof}

It follows that the equation of the \emph{gradient flow of $C$} is
%
\begin{equation*}
  \velocity \gamma = - \left(c - c_{0,\gamma} - (c_{1,\gamma} + c_{2,\gamma})\right) \ .
\end{equation*}

\begin{remark}
As $\grad C(\gamma)$ is the orthogonal projection of the cost $c$ onto the space of $\gamma$-interactions $B_{12}(\gamma)$, it is actually defined for all $\hat \gamma \in \Gamma(\mu_1,\mu_2)$. If $\hat \gamma$ is a zero of the gradient,
$\grad C(\hat \gamma) = 0$, then for all $(x,y) \in \suppof{\hat \gamma}$ it holds $c(x,y) = c_{0,\gamma} + c_{1,\gamma}(x,y) + c_{2,\gamma}(x,y)$.
\end{remark}

We expect any solution $t \mapsto \gamma(t)$ of the gradient flow to converge to a coupling $\bar\gamma = \lim_{t \to \infty} \gamma(t) \in \Delta(\Omega)$ such that $\expectat {\bar\gamma} c$ is the value of the Kantorovich optimal transport problem,
%
\begin{equation*}
  \expectat {\bar\gamma} c = \min \setof{\expectat \gamma c}{ \gamma \in \Gamma(\mu_1,\mu_2)} \ .
\end{equation*}

Notice that the extension of the gradient in \cref{eq:gradient} to $\Delta(\Omega)$ is zero at a $\widehat\gamma$, such that
%
\begin{equation*}
  c = c_{0,\widehat \gamma} + c_{1,\widehat \gamma} + c_{2,\widehat\gamma}
\end{equation*}
%
on $\suppof{\widehat\gamma}$. This should be compared with the
support properties of the optimal solutions of the Kantorovich problem, see \cite{santambrogio:2015otap}. For the finite state space case, see also \cite{pistone|rapallo|rogantin:2021} and \cite{montrucchio|pistone:2019-arxiv:1905.07547}.

\begin{remark}
  The splitting of the statistical bundle suggests that each $\gamma \in \Delta(\Omega_1\times\Omega_2)$ stays at the intersection of two orthogonal manifolds, namely, the  model with the margins of $\gamma$ and the additive exponential model $\euler^{u_1+u_2 - K_\gamma(u_1 + u_2)} \cdot \gamma$, $u_1 \in B_1(\gamma)$ and $u_2 \in B_2(\gamma)$.
\end{remark}

\begin{remark}
  The simplest non-trivial case is the toy example with $n_1=n_2=2$. Let us use the coding $\Omega_1=\Omega_2=\set{+1,-1}$. Any function $u$ on $\Omega$ has the pseudo-Boolean form $u(x,y)=a_0+a_1 x + a_2 y + a_{12} xy$. Notice that the monomials $1,x,y,xy$ are orthogonal in the counting measure. In particular, a probability has the form $\gamma(x,y) = \frac14(1+b_1x+b_2y+b_{12}xy)$ with margins $\mu_1(x) = \frac12(1+b_1x)$, $\mu_2(y) = \frac12(1+b_2y)$. The coefficients are the values of the moments. Given $b_1, b_2 \in ]-1,+1[$ to fix positive margins, the transport model is the 1-parameter family
\begin{equation*} \gamma(x,y;\theta) = \frac14(1+ b_1x+ b_2y+\theta xy)\ , \quad -1 + \avalof{b_1+b_2} \leq \theta \leq 1 - \avalof{b_1 - b_2} \ . \end{equation*}
The conditional probability functions are
\begin{gather*} \gamma_{1|2}(x|y) = \frac12 \left(1+\frac{b_1-b_2\theta}{1-b_2^2}x+\frac{-b_1b_2 + \theta}{1-b_2^2}xy\right) \\ \gamma_{2|1}(y|x) = \frac12 \left(1+\frac{b_2-b_1\theta}{1-b_1^2}y+\frac{-b_1b_2 + \theta}{1-b_1^2}xy\right) \end{gather*}
Let us compute the simple effects of a generic $u = \alpha_0 + \alpha_1 x + \alpha_2 y + \alpha_{12} xy$. We have $u_0 = \alpha_0 + \alpha_1 b_1 + \alpha_2 b_2 + \alpha_{12} \theta$, so that
\begin{equation*}
  u(x,y) - u_0 = \alpha_1 (x - b_1) + \alpha_2(y-b_2) + \alpha_{12} (xy - \theta) \ .
\end{equation*}
The simple effects are $u_1(x) + u_2(y) = \beta_1 (x - b_1) + \beta_2(y-b_2)$ and the orthogonality conditions $0 = \expectat \gamma {u_{12}(x - b_1)} = \expectat \gamma {u_{12}(y-b_2)}$ become
\begin{gather*}
  (\alpha_1-\beta_1)(1-b_1^2)+(\alpha_2-\beta_2)(\theta-b_1b_2) = - \alpha_{12}(b_2-\theta b_1) \ , \\
  (\alpha_1-\beta_1)(\theta-b_1b_2)+(\alpha_2-\beta_2)(1 - b_2^2)= - \alpha_{12}(b_1-\theta b_2) \ . 
\end{gather*}
The system has a unique closed-form solution. 
\end{remark}

\paragraph{Acknowledgments}
The author thanks three anonymous referees whose comments suggested a complete revision of the first version. The author thanks L. Malag\`o and L. Montrucchio for valuable suggestions. We first presented the gradient flow argument of \cref{sec:gradientflow} to the ``Computational information geometry for image and signal processing'' Conference, Sep 21--25 2015 ICMS, Edinburgh.

\bibliographystyle{splncs04}
\bibliography{tutto}
%

\end{document}


\paragraph{$\bm\diamond$}\emph{The terms $u_1$ and $u_2$ in \cref{eq:ANOVA} are characterized by the equations
%
\begin{equation}
\label{eq:projetion}
  \begin{aligned}
    \condexpectat \gamma {(u - u_0)} X u_1 + \condexpectat \gamma {(u-u_0)u_2} X &= 0 \ , \\
    \condexpectat \gamma {(u - u_0)u_1} Y + \condexpectat \gamma {(u-u_0)} Y u_2 &= 0 \ .
  \end{aligned}
%
\end{equation}}
